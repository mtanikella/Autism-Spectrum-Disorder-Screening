{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import model_selection\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Q1  Q2  Q3  Q4  Q5  Q6  Q7  Q8  Q9  Q10 Class\n",
      "0     1   1   1   1   0   0   1   1   0    0    NO\n",
      "1     1   1   0   1   0   0   0   1   0    1    NO\n",
      "2     1   1   0   1   1   0   1   1   1    1   YES\n",
      "3     1   1   0   1   0   0   1   1   0    1    NO\n",
      "4     1   0   0   0   0   0   0   1   0    0    NO\n",
      "5     1   1   1   1   1   0   1   1   1    1   YES\n",
      "6     0   1   0   0   0   0   0   1   0    0    NO\n",
      "7     1   1   1   1   0   0   0   0   1    0    NO\n",
      "8     1   1   0   0   1   0   0   1   1    1    NO\n",
      "9     1   1   1   1   0   1   1   1   1    0   YES\n",
      "10    1   1   1   1   1   1   1   1   1    1   YES\n",
      "11    0   1   0   1   1   1   1   0   0    1    NO\n",
      "12    0   1   1   1   1   1   0   0   1    0    NO\n",
      "13    1   0   0   0   0   0   1   1   0    1    NO\n",
      "14    1   0   0   0   0   0   1   1   0    1    NO\n",
      "15    1   1   0   1   1   0   0   1   0    1    NO\n",
      "16    1   0   0   0   0   0   1   1   1    1    NO\n",
      "17    0   0   0   0   0   0   0   1   0    1    NO\n",
      "18    0   0   1   0   1   1   0   0   0    0    NO\n",
      "19    0   0   0   0   0   0   1   1   0    1    NO\n",
      "20    0   1   1   1   0   0   0   0   0    0    NO\n",
      "21    0   0   0   0   0   0   0   0   0    0    NO\n",
      "22    0   0   0   1   0   0   1   1   1    1    NO\n",
      "23    0   0   0   0   0   0   0   1   0    1    NO\n",
      "24    1   1   1   1   0   0   0   1   0    0    NO\n",
      "25    0   1   1   0   0   0   0   1   0    0    NO\n",
      "26    0   0   0   0   0   0   0   1   0    0    NO\n",
      "27    0   0   0   0   0   0   0   1   0    0    NO\n",
      "28    0   0   0   0   0   0   0   1   0    0    NO\n",
      "29    0   1   1   0   0   0   0   0   1    1    NO\n",
      "..   ..  ..  ..  ..  ..  ..  ..  ..  ..  ...   ...\n",
      "674   1   1   0   0   1   1   0   1   0    1    NO\n",
      "675   1   1   1   1   0   0   0   0   1    0    NO\n",
      "676   1   1   0   0   0   0   1   0   0    1    NO\n",
      "677   1   0   0   0   0   0   1   0   0    1    NO\n",
      "678   1   1   1   1   1   0   0   1   1    1   YES\n",
      "679   1   1   1   1   1   1   1   1   1    1   YES\n",
      "680   1   1   1   1   1   1   1   1   1    1   YES\n",
      "681   1   1   0   1   1   1   1   1   1    1   YES\n",
      "682   1   1   0   0   0   0   0   1   0    0    NO\n",
      "683   1   1   0   0   0   0   0   1   1    0    NO\n",
      "684   1   0   1   0   0   0   0   1   0    1    NO\n",
      "685   1   0   1   1   1   0   0   1   1    1   YES\n",
      "686   1   0   0   0   1   0   1   1   0    1    NO\n",
      "687   1   1   1   0   1   1   1   1   1    1   YES\n",
      "688   1   0   1   1   1   1   1   0   1    1   YES\n",
      "689   1   0   0   0   1   1   1   1   1    1   YES\n",
      "690   0   0   0   0   1   0   0   0   0    0    NO\n",
      "691   1   0   0   1   0   0   1   1   0    0    NO\n",
      "692   1   1   1   0   1   1   1   1   0    1   YES\n",
      "693   1   0   0   1   0   0   0   1   0    1    NO\n",
      "694   1   1   1   1   1   0   0   1   0    1   YES\n",
      "695   1   0   1   1   0   0   1   1   0    0    NO\n",
      "696   1   1   1   1   1   1   0   1   1    1   YES\n",
      "697   1   1   1   1   1   0   0   0   0    1    NO\n",
      "698   1   1   1   1   1   1   1   1   1    1   YES\n",
      "699   0   1   0   1   1   0   1   1   1    1   YES\n",
      "700   1   0   0   0   0   0   0   1   0    1    NO\n",
      "701   1   0   1   1   1   0   1   1   0    1   YES\n",
      "702   1   0   0   1   1   0   1   0   1    1    NO\n",
      "703   1   0   1   1   1   0   1   1   1    1   YES\n",
      "\n",
      "[704 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv('/Users/Padma/Desktop/Mahit/science-fair-autism/Autism-Adult-Data-Processed2.csv')\n",
    "data = data.drop(\"Jaundice\", axis=1)\n",
    "data = data.drop(\"Total\", axis=1)\n",
    "data = data.drop(\"PDD\", axis=1)\n",
    "data = data.drop(\"Age\", axis=1)\n",
    "data = data.drop(\"Ethnicity\", axis=1)\n",
    "data = data.drop(\"Gender\", axis=1)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Q1  Q2  Q3  Q4  Q5  Q6  Q7  Q8  Q9  Q10 Class\n",
      "0   1   1   1   1   0   0   1   1   0    0    NO\n",
      "1   1   1   0   1   0   0   0   1   0    1    NO\n",
      "2   1   1   0   1   1   0   1   1   1    1   YES\n",
      "3   1   1   0   1   0   0   1   1   0    1    NO\n",
      "4   1   0   0   0   0   0   0   1   0    0    NO\n"
     ]
    }
   ],
   "source": [
    "print (data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1        int64\n",
      "Q2        int64\n",
      "Q3        int64\n",
      "Q4        int64\n",
      "Q5        int64\n",
      "Q6        int64\n",
      "Q7        int64\n",
      "Q8        int64\n",
      "Q9        int64\n",
      "Q10       int64\n",
      "Class    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print (data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label=LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for column in data.columns.values:\n",
    "    if data[column].dtypes=='object':\n",
    "        data_le=data[column]\n",
    "        label.fit(data_le.values)\n",
    "        data[column]=label.transform(data[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1       int64\n",
      "Q2       int64\n",
      "Q3       int64\n",
      "Q4       int64\n",
      "Q5       int64\n",
      "Q6       int64\n",
      "Q7       int64\n",
      "Q8       int64\n",
      "Q9       int64\n",
      "Q10      int64\n",
      "Class    int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print (data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Q1  Q2  Q3  Q4  Q5  Q6  Q7  Q8  Q9  Q10  Class\n",
      "0   1   1   1   1   0   0   1   1   0    0      0\n",
      "1   1   1   0   1   0   0   0   1   0    1      0\n",
      "2   1   1   0   1   1   0   1   1   1    1      1\n",
      "3   1   1   0   1   0   0   1   1   0    1      0\n",
      "4   1   0   0   0   0   0   0   1   0    0      0\n"
     ]
    }
   ],
   "source": [
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Q1  Q2  Q3  Q4  Q5  Q6  Q7  Q8  Q9  Q10  Class\n",
      "0     1   1   1   1   0   0   1   1   0    0      0\n",
      "1     1   1   0   1   0   0   0   1   0    1      0\n",
      "2     1   1   0   1   1   0   1   1   1    1      1\n",
      "3     1   1   0   1   0   0   1   1   0    1      0\n",
      "4     1   0   0   0   0   0   0   1   0    0      0\n",
      "5     1   1   1   1   1   0   1   1   1    1      1\n",
      "6     0   1   0   0   0   0   0   1   0    0      0\n",
      "7     1   1   1   1   0   0   0   0   1    0      0\n",
      "8     1   1   0   0   1   0   0   1   1    1      0\n",
      "9     1   1   1   1   0   1   1   1   1    0      1\n",
      "10    1   1   1   1   1   1   1   1   1    1      1\n",
      "11    0   1   0   1   1   1   1   0   0    1      0\n",
      "12    0   1   1   1   1   1   0   0   1    0      0\n",
      "13    1   0   0   0   0   0   1   1   0    1      0\n",
      "14    1   0   0   0   0   0   1   1   0    1      0\n",
      "15    1   1   0   1   1   0   0   1   0    1      0\n",
      "16    1   0   0   0   0   0   1   1   1    1      0\n",
      "17    0   0   0   0   0   0   0   1   0    1      0\n",
      "18    0   0   1   0   1   1   0   0   0    0      0\n",
      "19    0   0   0   0   0   0   1   1   0    1      0\n",
      "20    0   1   1   1   0   0   0   0   0    0      0\n",
      "21    0   0   0   0   0   0   0   0   0    0      0\n",
      "22    0   0   0   1   0   0   1   1   1    1      0\n",
      "23    0   0   0   0   0   0   0   1   0    1      0\n",
      "24    1   1   1   1   0   0   0   1   0    0      0\n",
      "25    0   1   1   0   0   0   0   1   0    0      0\n",
      "26    0   0   0   0   0   0   0   1   0    0      0\n",
      "27    0   0   0   0   0   0   0   1   0    0      0\n",
      "28    0   0   0   0   0   0   0   1   0    0      0\n",
      "29    0   1   1   0   0   0   0   0   1    1      0\n",
      "..   ..  ..  ..  ..  ..  ..  ..  ..  ..  ...    ...\n",
      "674   1   1   0   0   1   1   0   1   0    1      0\n",
      "675   1   1   1   1   0   0   0   0   1    0      0\n",
      "676   1   1   0   0   0   0   1   0   0    1      0\n",
      "677   1   0   0   0   0   0   1   0   0    1      0\n",
      "678   1   1   1   1   1   0   0   1   1    1      1\n",
      "679   1   1   1   1   1   1   1   1   1    1      1\n",
      "680   1   1   1   1   1   1   1   1   1    1      1\n",
      "681   1   1   0   1   1   1   1   1   1    1      1\n",
      "682   1   1   0   0   0   0   0   1   0    0      0\n",
      "683   1   1   0   0   0   0   0   1   1    0      0\n",
      "684   1   0   1   0   0   0   0   1   0    1      0\n",
      "685   1   0   1   1   1   0   0   1   1    1      1\n",
      "686   1   0   0   0   1   0   1   1   0    1      0\n",
      "687   1   1   1   0   1   1   1   1   1    1      1\n",
      "688   1   0   1   1   1   1   1   0   1    1      1\n",
      "689   1   0   0   0   1   1   1   1   1    1      1\n",
      "690   0   0   0   0   1   0   0   0   0    0      0\n",
      "691   1   0   0   1   0   0   1   1   0    0      0\n",
      "692   1   1   1   0   1   1   1   1   0    1      1\n",
      "693   1   0   0   1   0   0   0   1   0    1      0\n",
      "694   1   1   1   1   1   0   0   1   0    1      1\n",
      "695   1   0   1   1   0   0   1   1   0    0      0\n",
      "696   1   1   1   1   1   1   0   1   1    1      1\n",
      "697   1   1   1   1   1   0   0   0   0    1      0\n",
      "698   1   1   1   1   1   1   1   1   1    1      1\n",
      "699   0   1   0   1   1   0   1   1   1    1      1\n",
      "700   1   0   0   0   0   0   0   1   0    1      0\n",
      "701   1   0   1   1   1   0   1   1   0    1      1\n",
      "702   1   0   0   1   1   0   1   0   1    1      0\n",
      "703   1   0   1   1   1   0   1   1   1    1      1\n",
      "\n",
      "[704 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "print (data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Q1  Q2  Q3  Q4  Q5  Q6  Q7  Q8  Q9  Q10  Class\n",
      "699   0   1   0   1   1   0   1   1   1    1      1\n",
      "700   1   0   0   0   0   0   0   1   0    1      0\n",
      "701   1   0   1   1   1   0   1   1   0    1      1\n",
      "702   1   0   0   1   1   0   1   0   1    1      0\n",
      "703   1   0   1   1   1   0   1   1   1    1      1\n"
     ]
    }
   ],
   "source": [
    "print (data.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(704, 11)\n"
     ]
    }
   ],
   "source": [
    "print (data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class\n",
      "0    515\n",
      "1    189\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print (data.groupby('Class').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAACiCAYAAABh/yf0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a24037400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.plot(kind='box', subplots=True, layout=(5,4), sharex=False, sharey=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n9/8B7iSrLakeVbEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a22560ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Q1  Q2  Q3  Q4  Q5  Q6  Q7  Q8  Q9  Q10  Class\n",
      "0     1   1   1   1   0   0   1   1   0    0      0\n",
      "1     1   1   0   1   0   0   0   1   0    1      0\n",
      "2     1   1   0   1   1   0   1   1   1    1      1\n",
      "3     1   1   0   1   0   0   1   1   0    1      0\n",
      "4     1   0   0   0   0   0   0   1   0    0      0\n",
      "5     1   1   1   1   1   0   1   1   1    1      1\n",
      "6     0   1   0   0   0   0   0   1   0    0      0\n",
      "7     1   1   1   1   0   0   0   0   1    0      0\n",
      "8     1   1   0   0   1   0   0   1   1    1      0\n",
      "9     1   1   1   1   0   1   1   1   1    0      1\n",
      "10    1   1   1   1   1   1   1   1   1    1      1\n",
      "11    0   1   0   1   1   1   1   0   0    1      0\n",
      "12    0   1   1   1   1   1   0   0   1    0      0\n",
      "13    1   0   0   0   0   0   1   1   0    1      0\n",
      "14    1   0   0   0   0   0   1   1   0    1      0\n",
      "15    1   1   0   1   1   0   0   1   0    1      0\n",
      "16    1   0   0   0   0   0   1   1   1    1      0\n",
      "17    0   0   0   0   0   0   0   1   0    1      0\n",
      "18    0   0   1   0   1   1   0   0   0    0      0\n",
      "19    0   0   0   0   0   0   1   1   0    1      0\n",
      "20    0   1   1   1   0   0   0   0   0    0      0\n",
      "21    0   0   0   0   0   0   0   0   0    0      0\n",
      "22    0   0   0   1   0   0   1   1   1    1      0\n",
      "23    0   0   0   0   0   0   0   1   0    1      0\n",
      "24    1   1   1   1   0   0   0   1   0    0      0\n",
      "25    0   1   1   0   0   0   0   1   0    0      0\n",
      "26    0   0   0   0   0   0   0   1   0    0      0\n",
      "27    0   0   0   0   0   0   0   1   0    0      0\n",
      "28    0   0   0   0   0   0   0   1   0    0      0\n",
      "29    0   1   1   0   0   0   0   0   1    1      0\n",
      "..   ..  ..  ..  ..  ..  ..  ..  ..  ..  ...    ...\n",
      "674   1   1   0   0   1   1   0   1   0    1      0\n",
      "675   1   1   1   1   0   0   0   0   1    0      0\n",
      "676   1   1   0   0   0   0   1   0   0    1      0\n",
      "677   1   0   0   0   0   0   1   0   0    1      0\n",
      "678   1   1   1   1   1   0   0   1   1    1      1\n",
      "679   1   1   1   1   1   1   1   1   1    1      1\n",
      "680   1   1   1   1   1   1   1   1   1    1      1\n",
      "681   1   1   0   1   1   1   1   1   1    1      1\n",
      "682   1   1   0   0   0   0   0   1   0    0      0\n",
      "683   1   1   0   0   0   0   0   1   1    0      0\n",
      "684   1   0   1   0   0   0   0   1   0    1      0\n",
      "685   1   0   1   1   1   0   0   1   1    1      1\n",
      "686   1   0   0   0   1   0   1   1   0    1      0\n",
      "687   1   1   1   0   1   1   1   1   1    1      1\n",
      "688   1   0   1   1   1   1   1   0   1    1      1\n",
      "689   1   0   0   0   1   1   1   1   1    1      1\n",
      "690   0   0   0   0   1   0   0   0   0    0      0\n",
      "691   1   0   0   1   0   0   1   1   0    0      0\n",
      "692   1   1   1   0   1   1   1   1   0    1      1\n",
      "693   1   0   0   1   0   0   0   1   0    1      0\n",
      "694   1   1   1   1   1   0   0   1   0    1      1\n",
      "695   1   0   1   1   0   0   1   1   0    0      0\n",
      "696   1   1   1   1   1   1   0   1   1    1      1\n",
      "697   1   1   1   1   1   0   0   0   0    1      0\n",
      "698   1   1   1   1   1   1   1   1   1    1      1\n",
      "699   0   1   0   1   1   0   1   1   1    1      1\n",
      "700   1   0   0   0   0   0   0   1   0    1      0\n",
      "701   1   0   1   1   1   0   1   1   0    1      1\n",
      "702   1   0   0   1   1   0   1   0   1    1      0\n",
      "703   1   0   1   1   1   0   1   1   1    1      1\n",
      "\n",
      "[704 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "print (data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(704, 11)\n"
     ]
    }
   ],
   "source": [
    "array = data.values\n",
    "print (array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = array[:,0:9]\n",
    "Y = array[:,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 ..., 1 1 0]\n",
      " [1 1 0 ..., 0 1 0]\n",
      " [1 1 0 ..., 1 1 1]\n",
      " ..., \n",
      " [1 0 1 ..., 1 1 0]\n",
      " [1 0 0 ..., 1 0 1]\n",
      " [1 0 1 ..., 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "print (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0\n",
      " 0 1 1 1 0 0 0 1 1 0 0 0 0 0 1 0 1 1 1 1 1 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1\n",
      " 0 0 0 1 1 1 0 1 1 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1\n",
      " 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 1 0 1 0 0 0 0 1 1 1 1 0 1 0 1 1 0 1 1 1 0 1 1 0 0 0 0 1 0 0 1 0 0 0\n",
      " 0 1 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 0 1 0 0 1 1 1 0 0 0 0 0 1 1 1 0 0 0 1\n",
      " 1 1 0 1 0 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 1\n",
      " 1 0 1 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 1 1 0 0 1 0 0 1 0 0 0 1 0 1 1 0 0 1 1 0 1\n",
      " 0 0 1 1 1 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 1 1 1 1 0 0 0 1 0 0 0 1 1\n",
      " 0 0 0 1 0 1 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 1 1 0 0 0 0 1 1 0 1 1 1 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 1 1 1 0 0 0 1\n",
      " 0 0 0 1 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 1 0 1 1 1 0 0 1 0 1 0 1 0 1 1 0 1 0\n",
      " 1]\n"
     ]
    }
   ],
   "source": [
    "print (Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(704,)\n"
     ]
    }
   ],
   "source": [
    "validation_size=0.20\n",
    "seed=7\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train , X_validation, Y_train, Y_validation=model_selection.train_test_split(X,Y,test_size=validation_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(563, 9)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(141, 9)\n"
     ]
    }
   ],
   "source": [
    "print(X_validation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "lgr=linear_model.LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 614,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgr.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions=lgr.predict(X_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(Y_validation,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[97  0]\n",
      " [ 0 44]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(Y_validation,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        97\n",
      "          1       1.00      1.00      1.00        44\n",
      "\n",
      "avg / total       1.00      1.00      1.00       141\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_validation,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "dt=tree.DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 624,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions=dt.predict(X_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.964539007092\n",
      "[[95  2]\n",
      " [ 3 41]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.98      0.97        97\n",
      "          1       0.95      0.93      0.94        44\n",
      "\n",
      "avg / total       0.96      0.96      0.96       141\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(Y_validation,predictions))\n",
    "print(confusion_matrix(Y_validation,predictions))\n",
    "print(classification_report(Y_validation,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb=GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gnb.fit(X_train,Y_train)\n",
    "predictions=gnb.predict(X_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.978723404255\n",
      "[[95  2]\n",
      " [ 1 43]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.98      0.98        97\n",
      "          1       0.96      0.98      0.97        44\n",
      "\n",
      "avg / total       0.98      0.98      0.98       141\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(Y_validation,predictions))\n",
    "print(confusion_matrix(Y_validation,predictions))\n",
    "print(classification_report(Y_validation,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "vm=svm.SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vm.fit(X_train,Y_train)\n",
    "predictions=vm.predict(X_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.964539007092\n",
      "[[96  1]\n",
      " [ 4 40]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.99      0.97        97\n",
      "          1       0.98      0.91      0.94        44\n",
      "\n",
      "avg / total       0.96      0.96      0.96       141\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(Y_validation,predictions))\n",
    "print(confusion_matrix(Y_validation,predictions))\n",
    "print(classification_report(Y_validation,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense \n",
    "import numpy as np\n",
    "dataset=pd.read_csv('/Users/padma/Desktop/Mahit/science-fair-autism/Autism-Adult-Data-Processed2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=array[:,0:9]\n",
    "Y=array[:,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn=Sequential()\n",
    "nn.add(Dense(12,input_dim=9,activation='relu'))\n",
    "nn.add(Dense(8,activation='relu'))\n",
    "nn.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "563/563 [==============================] - 0s 297us/step - loss: 0.0354 - acc: 0.9876\n",
      "Epoch 2/150\n",
      "563/563 [==============================] - 0s 255us/step - loss: 0.0337 - acc: 0.9858\n",
      "Epoch 3/150\n",
      "563/563 [==============================] - 0s 259us/step - loss: 0.0361 - acc: 0.9858\n",
      "Epoch 4/150\n",
      "563/563 [==============================] - 0s 252us/step - loss: 0.0340 - acc: 0.9840\n",
      "Epoch 5/150\n",
      "563/563 [==============================] - 0s 263us/step - loss: 0.0412 - acc: 0.9840\n",
      "Epoch 6/150\n",
      "563/563 [==============================] - 0s 285us/step - loss: 0.0343 - acc: 0.9822\n",
      "Epoch 7/150\n",
      "563/563 [==============================] - 0s 278us/step - loss: 0.0353 - acc: 0.9840\n",
      "Epoch 8/150\n",
      "563/563 [==============================] - 0s 248us/step - loss: 0.0361 - acc: 0.9822\n",
      "Epoch 9/150\n",
      "563/563 [==============================] - 0s 263us/step - loss: 0.0391 - acc: 0.9840\n",
      "Epoch 10/150\n",
      "563/563 [==============================] - 0s 274us/step - loss: 0.0369 - acc: 0.9822\n",
      "Epoch 11/150\n",
      "563/563 [==============================] - 0s 272us/step - loss: 0.0351 - acc: 0.9876\n",
      "Epoch 12/150\n",
      "563/563 [==============================] - 0s 251us/step - loss: 0.0347 - acc: 0.9822\n",
      "Epoch 13/150\n",
      "563/563 [==============================] - 0s 250us/step - loss: 0.0365 - acc: 0.9840\n",
      "Epoch 14/150\n",
      "563/563 [==============================] - 0s 253us/step - loss: 0.0353 - acc: 0.9840\n",
      "Epoch 15/150\n",
      "563/563 [==============================] - 0s 256us/step - loss: 0.0351 - acc: 0.9840\n",
      "Epoch 16/150\n",
      "563/563 [==============================] - 0s 266us/step - loss: 0.0346 - acc: 0.9840\n",
      "Epoch 17/150\n",
      "563/563 [==============================] - 0s 251us/step - loss: 0.0385 - acc: 0.9840\n",
      "Epoch 18/150\n",
      "563/563 [==============================] - 0s 259us/step - loss: 0.0346 - acc: 0.9840\n",
      "Epoch 19/150\n",
      "563/563 [==============================] - 0s 275us/step - loss: 0.0345 - acc: 0.9840\n",
      "Epoch 20/150\n",
      "563/563 [==============================] - 0s 263us/step - loss: 0.0337 - acc: 0.9858\n",
      "Epoch 21/150\n",
      "563/563 [==============================] - 0s 291us/step - loss: 0.0347 - acc: 0.9858\n",
      "Epoch 22/150\n",
      "563/563 [==============================] - 0s 275us/step - loss: 0.0342 - acc: 0.9822\n",
      "Epoch 23/150\n",
      "563/563 [==============================] - 0s 307us/step - loss: 0.0336 - acc: 0.9840\n",
      "Epoch 24/150\n",
      "563/563 [==============================] - 0s 292us/step - loss: 0.0331 - acc: 0.9858\n",
      "Epoch 25/150\n",
      "563/563 [==============================] - 0s 271us/step - loss: 0.0358 - acc: 0.9822\n",
      "Epoch 26/150\n",
      "563/563 [==============================] - 0s 266us/step - loss: 0.0335 - acc: 0.9822\n",
      "Epoch 27/150\n",
      "563/563 [==============================] - 0s 270us/step - loss: 0.0374 - acc: 0.9840\n",
      "Epoch 28/150\n",
      "563/563 [==============================] - 0s 255us/step - loss: 0.0351 - acc: 0.9840\n",
      "Epoch 29/150\n",
      "563/563 [==============================] - 0s 263us/step - loss: 0.0341 - acc: 0.9822\n",
      "Epoch 30/150\n",
      "563/563 [==============================] - 0s 259us/step - loss: 0.0335 - acc: 0.9840\n",
      "Epoch 31/150\n",
      "563/563 [==============================] - 0s 252us/step - loss: 0.0347 - acc: 0.9822\n",
      "Epoch 32/150\n",
      "563/563 [==============================] - 0s 254us/step - loss: 0.0334 - acc: 0.9858\n",
      "Epoch 33/150\n",
      "563/563 [==============================] - 0s 257us/step - loss: 0.0339 - acc: 0.9805\n",
      "Epoch 34/150\n",
      "563/563 [==============================] - 0s 268us/step - loss: 0.0364 - acc: 0.9840\n",
      "Epoch 35/150\n",
      "563/563 [==============================] - 0s 262us/step - loss: 0.0328 - acc: 0.9876\n",
      "Epoch 36/150\n",
      "563/563 [==============================] - 0s 262us/step - loss: 0.0332 - acc: 0.9876\n",
      "Epoch 37/150\n",
      "563/563 [==============================] - 0s 274us/step - loss: 0.0355 - acc: 0.9840\n",
      "Epoch 38/150\n",
      "563/563 [==============================] - 0s 256us/step - loss: 0.0367 - acc: 0.9805\n",
      "Epoch 39/150\n",
      "563/563 [==============================] - 0s 254us/step - loss: 0.0345 - acc: 0.9858\n",
      "Epoch 40/150\n",
      "563/563 [==============================] - 0s 279us/step - loss: 0.0351 - acc: 0.9822\n",
      "Epoch 41/150\n",
      "563/563 [==============================] - 0s 263us/step - loss: 0.0327 - acc: 0.9858\n",
      "Epoch 42/150\n",
      "563/563 [==============================] - 0s 279us/step - loss: 0.0373 - acc: 0.9787\n",
      "Epoch 43/150\n",
      "563/563 [==============================] - 0s 246us/step - loss: 0.0358 - acc: 0.9858\n",
      "Epoch 44/150\n",
      "563/563 [==============================] - 0s 252us/step - loss: 0.0356 - acc: 0.9805\n",
      "Epoch 45/150\n",
      "563/563 [==============================] - 0s 265us/step - loss: 0.0329 - acc: 0.9858 0s - loss: 0.0229 - acc: 0.99\n",
      "Epoch 46/150\n",
      "563/563 [==============================] - 0s 277us/step - loss: 0.0326 - acc: 0.9858\n",
      "Epoch 47/150\n",
      "563/563 [==============================] - 0s 284us/step - loss: 0.0336 - acc: 0.9876\n",
      "Epoch 48/150\n",
      "563/563 [==============================] - 0s 271us/step - loss: 0.0331 - acc: 0.9822\n",
      "Epoch 49/150\n",
      "563/563 [==============================] - 0s 361us/step - loss: 0.0325 - acc: 0.9858\n",
      "Epoch 50/150\n",
      "563/563 [==============================] - 0s 291us/step - loss: 0.0344 - acc: 0.9858\n",
      "Epoch 51/150\n",
      "563/563 [==============================] - 0s 257us/step - loss: 0.0326 - acc: 0.9822\n",
      "Epoch 52/150\n",
      "563/563 [==============================] - 0s 297us/step - loss: 0.0341 - acc: 0.9840\n",
      "Epoch 53/150\n",
      "563/563 [==============================] - 0s 289us/step - loss: 0.0331 - acc: 0.9822\n",
      "Epoch 54/150\n",
      "563/563 [==============================] - 0s 272us/step - loss: 0.0331 - acc: 0.9840\n",
      "Epoch 55/150\n",
      "563/563 [==============================] - 0s 296us/step - loss: 0.0325 - acc: 0.9822\n",
      "Epoch 56/150\n",
      "563/563 [==============================] - 0s 262us/step - loss: 0.0347 - acc: 0.9822\n",
      "Epoch 57/150\n",
      "563/563 [==============================] - 0s 287us/step - loss: 0.0341 - acc: 0.9822\n",
      "Epoch 58/150\n",
      "563/563 [==============================] - 0s 264us/step - loss: 0.0367 - acc: 0.9876\n",
      "Epoch 59/150\n",
      "563/563 [==============================] - 0s 261us/step - loss: 0.0329 - acc: 0.9876\n",
      "Epoch 60/150\n",
      "563/563 [==============================] - 0s 277us/step - loss: 0.0354 - acc: 0.9822\n",
      "Epoch 61/150\n",
      "563/563 [==============================] - 0s 298us/step - loss: 0.0328 - acc: 0.9840\n",
      "Epoch 62/150\n",
      "563/563 [==============================] - 0s 276us/step - loss: 0.0327 - acc: 0.9822\n",
      "Epoch 63/150\n",
      "563/563 [==============================] - 0s 281us/step - loss: 0.0322 - acc: 0.9858\n",
      "Epoch 64/150\n",
      "563/563 [==============================] - 0s 261us/step - loss: 0.0318 - acc: 0.9840\n",
      "Epoch 65/150\n",
      "563/563 [==============================] - 0s 269us/step - loss: 0.0329 - acc: 0.9805\n",
      "Epoch 66/150\n",
      "563/563 [==============================] - 0s 292us/step - loss: 0.0323 - acc: 0.9840\n",
      "Epoch 67/150\n",
      "563/563 [==============================] - 0s 291us/step - loss: 0.0340 - acc: 0.9822\n",
      "Epoch 68/150\n",
      "563/563 [==============================] - 0s 285us/step - loss: 0.0330 - acc: 0.9822\n",
      "Epoch 69/150\n",
      "563/563 [==============================] - 0s 248us/step - loss: 0.0343 - acc: 0.9822\n",
      "Epoch 70/150\n",
      "563/563 [==============================] - 0s 306us/step - loss: 0.0351 - acc: 0.9805\n",
      "Epoch 71/150\n",
      "563/563 [==============================] - 0s 289us/step - loss: 0.0374 - acc: 0.9805\n",
      "Epoch 72/150\n",
      "563/563 [==============================] - 0s 306us/step - loss: 0.0299 - acc: 0.9876\n",
      "Epoch 73/150\n",
      "563/563 [==============================] - 0s 290us/step - loss: 0.0399 - acc: 0.9751\n",
      "Epoch 74/150\n",
      "563/563 [==============================] - 0s 294us/step - loss: 0.0346 - acc: 0.9840\n",
      "Epoch 75/150\n",
      "563/563 [==============================] - 0s 277us/step - loss: 0.0374 - acc: 0.9840\n",
      "Epoch 76/150\n",
      "563/563 [==============================] - 0s 308us/step - loss: 0.0326 - acc: 0.9822\n",
      "Epoch 77/150\n",
      "563/563 [==============================] - 0s 277us/step - loss: 0.0336 - acc: 0.9822\n",
      "Epoch 78/150\n",
      "563/563 [==============================] - 0s 271us/step - loss: 0.0321 - acc: 0.9840\n",
      "Epoch 79/150\n",
      "563/563 [==============================] - 0s 285us/step - loss: 0.0345 - acc: 0.9805\n",
      "Epoch 80/150\n",
      "563/563 [==============================] - 0s 296us/step - loss: 0.0344 - acc: 0.9805\n",
      "Epoch 81/150\n",
      "563/563 [==============================] - 0s 270us/step - loss: 0.0321 - acc: 0.9840\n",
      "Epoch 82/150\n",
      "563/563 [==============================] - 0s 267us/step - loss: 0.0333 - acc: 0.9805\n",
      "Epoch 83/150\n",
      "563/563 [==============================] - 0s 270us/step - loss: 0.0319 - acc: 0.9840\n",
      "Epoch 84/150\n",
      "563/563 [==============================] - 0s 289us/step - loss: 0.0336 - acc: 0.9822\n",
      "Epoch 85/150\n",
      "563/563 [==============================] - 0s 262us/step - loss: 0.0343 - acc: 0.9822\n",
      "Epoch 86/150\n",
      "563/563 [==============================] - 0s 266us/step - loss: 0.0328 - acc: 0.9840\n",
      "Epoch 87/150\n",
      "563/563 [==============================] - 0s 261us/step - loss: 0.0327 - acc: 0.9858\n",
      "Epoch 88/150\n",
      "563/563 [==============================] - 0s 261us/step - loss: 0.0328 - acc: 0.9840\n",
      "Epoch 89/150\n",
      "563/563 [==============================] - 0s 281us/step - loss: 0.0317 - acc: 0.9840\n",
      "Epoch 90/150\n",
      "563/563 [==============================] - 0s 285us/step - loss: 0.0314 - acc: 0.9822\n",
      "Epoch 91/150\n",
      "563/563 [==============================] - 0s 250us/step - loss: 0.0322 - acc: 0.9822\n",
      "Epoch 92/150\n",
      "563/563 [==============================] - 0s 255us/step - loss: 0.0319 - acc: 0.9840\n",
      "Epoch 93/150\n",
      "563/563 [==============================] - 0s 268us/step - loss: 0.0331 - acc: 0.9840 0s - loss: 0.0286 - acc: 0.98\n",
      "Epoch 94/150\n",
      "563/563 [==============================] - 0s 290us/step - loss: 0.0338 - acc: 0.9840\n",
      "Epoch 95/150\n",
      "563/563 [==============================] - 0s 268us/step - loss: 0.0348 - acc: 0.9805\n",
      "Epoch 96/150\n",
      "563/563 [==============================] - 0s 265us/step - loss: 0.0332 - acc: 0.9805\n",
      "Epoch 97/150\n",
      "563/563 [==============================] - 0s 271us/step - loss: 0.0326 - acc: 0.9805\n",
      "Epoch 98/150\n",
      "563/563 [==============================] - 0s 277us/step - loss: 0.0318 - acc: 0.9840\n",
      "Epoch 99/150\n",
      "563/563 [==============================] - 0s 276us/step - loss: 0.0340 - acc: 0.9822\n",
      "Epoch 100/150\n",
      "563/563 [==============================] - 0s 252us/step - loss: 0.0342 - acc: 0.9876\n",
      "Epoch 101/150\n",
      "563/563 [==============================] - 0s 259us/step - loss: 0.0299 - acc: 0.9876\n",
      "Epoch 102/150\n",
      "563/563 [==============================] - 0s 268us/step - loss: 0.0313 - acc: 0.9822\n",
      "Epoch 103/150\n",
      "563/563 [==============================] - 0s 270us/step - loss: 0.0317 - acc: 0.9822\n",
      "Epoch 104/150\n",
      "563/563 [==============================] - 0s 275us/step - loss: 0.0357 - acc: 0.9751\n",
      "Epoch 105/150\n",
      "563/563 [==============================] - 0s 262us/step - loss: 0.0317 - acc: 0.9840\n",
      "Epoch 106/150\n",
      "563/563 [==============================] - 0s 259us/step - loss: 0.0322 - acc: 0.9858\n",
      "Epoch 107/150\n",
      "563/563 [==============================] - 0s 262us/step - loss: 0.0331 - acc: 0.9858\n",
      "Epoch 108/150\n",
      "563/563 [==============================] - 0s 294us/step - loss: 0.0326 - acc: 0.9822\n",
      "Epoch 109/150\n",
      "563/563 [==============================] - 0s 315us/step - loss: 0.0310 - acc: 0.9822\n",
      "Epoch 110/150\n",
      "563/563 [==============================] - 0s 261us/step - loss: 0.0320 - acc: 0.9840\n",
      "Epoch 111/150\n",
      "563/563 [==============================] - 0s 260us/step - loss: 0.0329 - acc: 0.9840\n",
      "Epoch 112/150\n",
      "563/563 [==============================] - 0s 266us/step - loss: 0.0326 - acc: 0.9822\n",
      "Epoch 113/150\n",
      "563/563 [==============================] - 0s 273us/step - loss: 0.0326 - acc: 0.9822\n",
      "Epoch 114/150\n",
      "563/563 [==============================] - 0s 289us/step - loss: 0.0331 - acc: 0.9840\n",
      "Epoch 115/150\n",
      "563/563 [==============================] - 0s 270us/step - loss: 0.0316 - acc: 0.9840\n",
      "Epoch 116/150\n",
      "563/563 [==============================] - 0s 264us/step - loss: 0.0311 - acc: 0.9805\n",
      "Epoch 117/150\n",
      "563/563 [==============================] - 0s 290us/step - loss: 0.0314 - acc: 0.9822\n",
      "Epoch 118/150\n",
      "563/563 [==============================] - 0s 280us/step - loss: 0.0305 - acc: 0.9840\n",
      "Epoch 119/150\n",
      "563/563 [==============================] - 0s 268us/step - loss: 0.0334 - acc: 0.9840\n",
      "Epoch 120/150\n",
      "563/563 [==============================] - 0s 277us/step - loss: 0.0362 - acc: 0.9805\n",
      "Epoch 121/150\n",
      "563/563 [==============================] - 0s 262us/step - loss: 0.0326 - acc: 0.9822\n",
      "Epoch 122/150\n",
      "563/563 [==============================] - 0s 263us/step - loss: 0.0330 - acc: 0.9822\n",
      "Epoch 123/150\n",
      "563/563 [==============================] - 0s 299us/step - loss: 0.0337 - acc: 0.9822\n",
      "Epoch 124/150\n",
      "563/563 [==============================] - 0s 273us/step - loss: 0.0318 - acc: 0.9858\n",
      "Epoch 125/150\n",
      "563/563 [==============================] - 0s 282us/step - loss: 0.0315 - acc: 0.9805\n",
      "Epoch 126/150\n",
      "563/563 [==============================] - 0s 258us/step - loss: 0.0307 - acc: 0.9840\n",
      "Epoch 127/150\n",
      "563/563 [==============================] - 0s 256us/step - loss: 0.0317 - acc: 0.9822\n",
      "Epoch 128/150\n",
      "563/563 [==============================] - 0s 268us/step - loss: 0.0334 - acc: 0.9787\n",
      "Epoch 129/150\n",
      "563/563 [==============================] - 0s 283us/step - loss: 0.0354 - acc: 0.9822\n",
      "Epoch 130/150\n",
      "563/563 [==============================] - 0s 297us/step - loss: 0.0317 - acc: 0.9822\n",
      "Epoch 131/150\n",
      "563/563 [==============================] - 0s 268us/step - loss: 0.0348 - acc: 0.9787\n",
      "Epoch 132/150\n",
      "563/563 [==============================] - 0s 258us/step - loss: 0.0301 - acc: 0.9858\n",
      "Epoch 133/150\n",
      "563/563 [==============================] - 0s 255us/step - loss: 0.0349 - acc: 0.9822\n",
      "Epoch 134/150\n",
      "563/563 [==============================] - 0s 260us/step - loss: 0.0339 - acc: 0.9840\n",
      "Epoch 135/150\n",
      "563/563 [==============================] - 0s 265us/step - loss: 0.0329 - acc: 0.9769\n",
      "Epoch 136/150\n",
      "563/563 [==============================] - 0s 270us/step - loss: 0.0304 - acc: 0.9876\n",
      "Epoch 137/150\n",
      "563/563 [==============================] - 0s 265us/step - loss: 0.0317 - acc: 0.9822\n",
      "Epoch 138/150\n",
      "563/563 [==============================] - 0s 257us/step - loss: 0.0358 - acc: 0.9840\n",
      "Epoch 139/150\n",
      "563/563 [==============================] - 0s 258us/step - loss: 0.0337 - acc: 0.9822\n",
      "Epoch 140/150\n",
      "563/563 [==============================] - 0s 272us/step - loss: 0.0303 - acc: 0.9840ETA: 0s - loss: 0.0174 - acc: 1.0000  \n",
      "Epoch 141/150\n",
      "563/563 [==============================] - 0s 257us/step - loss: 0.0329 - acc: 0.9876\n",
      "Epoch 142/150\n",
      "563/563 [==============================] - 0s 261us/step - loss: 0.0330 - acc: 0.9840\n",
      "Epoch 143/150\n",
      "563/563 [==============================] - 0s 257us/step - loss: 0.0326 - acc: 0.9840\n",
      "Epoch 144/150\n",
      "563/563 [==============================] - 0s 250us/step - loss: 0.0312 - acc: 0.9805\n",
      "Epoch 145/150\n",
      "563/563 [==============================] - 0s 267us/step - loss: 0.0317 - acc: 0.9840\n",
      "Epoch 146/150\n",
      "563/563 [==============================] - 0s 267us/step - loss: 0.0312 - acc: 0.9805\n",
      "Epoch 147/150\n",
      "563/563 [==============================] - 0s 244us/step - loss: 0.0325 - acc: 0.9822\n",
      "Epoch 148/150\n",
      "563/563 [==============================] - 0s 246us/step - loss: 0.0324 - acc: 0.9822\n",
      "Epoch 149/150\n",
      "563/563 [==============================] - 0s 249us/step - loss: 0.0340 - acc: 0.9840\n",
      "Epoch 150/150\n",
      "563/563 [==============================] - 0s 264us/step - loss: 0.0307 - acc: 0.9840\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a247ac278>"
      ]
     },
     "execution_count": 645,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.fit(X_train, Y_train, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 0s 866us/step\n"
     ]
    }
   ],
   "source": [
    "predictions=nn.evaluate(X_validation,Y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "acc: 98.58%\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n%s: %.2f%%\" % (nn.metrics_names[1], predictions[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
